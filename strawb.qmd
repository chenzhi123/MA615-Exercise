---
title: "Stawberries: exploratory data analysis"
author: Zengqi Chen
date: 2023 Oct 11
format: html
engine: knitr
---

## Data acquisition and assessment
```{r setup, include=FALSE}
#| label: Load libraries
#| warning: false
#| message: false
#| echo: false
knitr::opts_chunk$set(echo = TRUE,warning=FALSE)
library(knitr)  
library(kableExtra)
library(tidyverse)
library(stringr)
library(ggplot2)
library(reshape2)
```

<!-- Read the file -->

```{r warning=FALSE, message=FALSE}
#| label: read data - glimpse 
#| warning: false
#| message: false
#| echo: false
strawberry <- read_csv("strawberry.csv", col_names = TRUE)

glimpse(strawberry)
```
```{r}
state <- table(strawberry$State)
barplot(state, main="Distribution of the number of data entries by state", las=2)



```

```{r}
barplot(table(strawberry$Year), main="Distribution of the number of data entries by year", las=2)
```
```{r}
barplot(table(strawberry$Domain), main="Distribution of the number of data entries by Domain", las=2)
```




## Data cleaning and organization

<!-- Remove columns with a single value in all columns -->

```{r}
#| label: drop one-item columns
#| echo: false
strawberry$Value <- as.numeric(as.character(strawberry$Value), na.rm=F)

## define function
drop_one_value_col <- function(df){
col_name <- NULL
col_val <- NULL
suppressWarnings({
for(i in 1:dim(df)[2]){
if((df |> distinct(df[,i]) |> count()) == 1){
  col_name = c(col_name, colnames(df[i]))
  col_val = c(col_val, df[1,i])  
} }
})

if(is.null(col_name)){return("No Columns to drop")}else{
   col_val = unlist(col_val)
   attributes(col_val) = NULL
   drp = data.frame(col_name, col_val)
   return(drp)
   }
}

str <- drop_one_value_col(strawberry)

# str |> kable(caption = "Dropped Single-Value Columns: names and values")

str <- str$col_name

strawberry <- strawberry |> select(!all_of(str))



## applying the function a second time 
## tests the function when there aren't any 
## one-value columns
##  drop_one_value_col(strawberry)

```

<!-- Glimpse of strawberry data after dropping single-value columns. -->

```{r}
#| label: glimpse of strawberry data
#| echo: false

glimpse(strawberry)

```


```{r}
#| label: examine California data
#| echo: false

## filter rows of California data from the CENSUS data
calif_census <- strawberry |> filter((State=="CALIFORNIA") & (Program=="CENSUS"))


## ## filter rows of California data from the SURVEY data
calif_survey <- strawberry |> filter((State=="CALIFORNIA") & (Program=="SURVEY"))

census_col <- colnames(calif_census)

survey_col <- colnames(calif_survey)

```


```{r}
#| label: split srawberry into census and survey pieces
#| echo: false

strwb_census <- strawberry |> filter(Program == "CENSUS")

strwb_survey <- strawberry |> filter(Program == "SURVEY")


rm(calif_census, calif_survey)

strwb_census <- strwb_census |>
  separate_wider_delim(  cols = `Data Item`,
                         delim = ",",
                         names = c("Fruit",
                                 "temp1",
                                 "temp2",
                                 "temp3"),
                         too_many = "error",
                         too_few = "align_start"
                       )


## split temp1 into crop_type, Prop_acct

strwb_census <- strwb_census |>
  separate_wider_delim(  cols = temp1,
                         delim = " - ",
                         names = c("crop_type",
                                 "prop_acct"),
                         too_many = "error",
                         too_few = "align_start"
                       )

# glimpse(strwb_census)

strwb_census$crop_type <- str_trim(strwb_census$crop_type, side = "both")

strwb_census$temp2 <- str_trim(strwb_census$temp2, side = "both")

strwb_census$temp3 <- str_trim(strwb_census$temp3, side = "both")


strwb_census <- strwb_census |> mutate(`Fresh Market` = temp2, .after = temp2)

## Remove cells in `Fresh Market` column 
##   that begin "MEASURED"
strwb_census$`Fresh Market` <- strwb_census$`Fresh Market` |> str_replace( "^MEA.*", "")

## Remove cells in `Fresh Market` column 
##   that begin "PROCESSING" 
strwb_census$`Fresh Market` <- strwb_census$`Fresh Market` |> str_replace( "^P.*", "")

## substitute a space for NA in `Fresh Market` column
strwb_census$`Fresh Market`[is.na(strwb_census$`Fresh Market`)] <- ""  

## in temp2 column, remove cells that begin "FRESH"
 strwb_census$temp2 <- strwb_census$temp2 |> str_replace("^F.*", "")

## Now fix the entries in the `Fresh Market` column
##   Remove "FRESH MARKET - " from the cells
strwb_census$`Fresh Market` <- strwb_census$`Fresh Market` |> str_replace("^FRESH MARKET - ", "")


## Make a copy of temp2 named `Process Market`
strwb_census <- strwb_census |> mutate(`Process Market` = temp2, .after = temp2)

## remove `Process Market` cells beginning "MEASURED"
strwb_census$`Process Market` <-  strwb_census$`Process Market` |> str_replace("^MEA.*", "")

## substitute space for NA in `Process Market` column
strwb_census$`Process Market`[is.na(strwb_census$`Process Market`)] <- ""

## In temp2, remove cells that begin "PROCESSING"
strwb_census$temp2 <- strwb_census$temp2 |> str_replace("^P.*", "")

## In `Processing Market`, remove "PROCESSING - " from cells
strwb_census$`Process Market` <-  strwb_census$`Process Market` |> str_replace("PROCESSING - ", "") 


## substitute a space for NA in prop_acct column
strwb_census$prop_acct[is.na(strwb_census$prop_acct)] <- "" 

## substitute a space for NA in temp2 column
strwb_census$temp2[is.na(strwb_census$temp2)] <- "" 

## substitute a space for NA in temp2 column
strwb_census$temp3[is.na(strwb_census$temp3)] <- "" 


strwb_census <- strwb_census |> unite(temp2, temp3, col="Metric", sep="")

## Now fix the entries in the Metric column
##   Remove "MEASURED IN " from the cells
strwb_census$Metric <- strwb_census$Metric |> str_replace("MEASURED IN ", "")

## move Metric to the end
strwb_census <- strwb_census |> relocate(Metric, .before = Domain)

#strwb_census <- strwb_census |> relocate(`Process Market`, .before = Metric)

strwb_census <- strwb_census |> rename(Totals = prop_acct)

#drop_one_value_col(strwb_census)


```

<!-- ## The Value column transformation -->

```{r}
#| label: define functions dcomma and footnote finder
#| echo: false
#| warning: false
#| message: false
#| eval: true


vals <- strwb_census$Value


g1 <- sub(",", "", vals)
# vals[1:20]
# g1[1:20]


g2 <- gsub(",", "", vals)
# vals[1:20]
# g2[1:20]


## stringr - str_replace(), str_replace_all()

## LOOK -- see ref for stingr pkg
a <- vals |> str_detect(",")

# vals[1:20]
# a[1:20]

## Still strings!!

b <- vals |> str_replace(",", "")
# vals[1:20]
# b[1:20]

c <- vals |> str_replace_all(",", "")
# vals[1:20]
# c[1:20]

## Now notice what happens when the
## the strings of digits are cast to numerics.

## for example
c <- as.numeric(c)
# c[1:20]


### remove commas from Value entries
dcomma <- function(c){
  x_new <- as.numeric(gsub(",", "", c))
  return(x_new)
}



#########################################  footnotes

## finds single uppor case Character in parens in s2
## e.g. "(D)"

## To fine the location and value of the footnotes

v <- strwb_census$Value


## find the footnote locations
## fn_i: locations 
fn_i <- v |> str_detect("^\\([:upper:]\\)$") ## returns


## dcomma returns numbers and NA's
v1 <- dcomma(v)

## locations of NA's
na_i <- is.na(v1)

dcomma <- function(c){
  suppressWarnings({
  xnew = as.numeric(gsub(",", "", c))
  fns = unique(c[is.na(xnew)])
  vtran = list("new_vec" = xnew, "footnotes" = fns)
  return(vtran)
  })
}

 
v_trns <- dcomma(v)
 

 a <- v_trns$new_vec
 # a[1:20]
 
 # v_trns$footnotes
 

```

## EDA

The plot displays the total strawberry production by state. States are arranged from highest to lowest production. The taller the bar, the more strawberries that state produces. From the plot, we can quickly identify which states are the major producers and which produce fewer strawberries. This visualization helps stakeholders quickly gauge regional strawberry production patterns.
```{r}
strawberry <- read.csv("strawberry.csv", stringsAsFactors = FALSE)

# Filter rows where the Data Item column mentions 'PRODUCTION'
production_data <- strawberry[grep('PRODUCTION', strawberry$Data.Item),]

# Convert non-numeric values in the Value column to NA
production_data$Value <- as.numeric(production_data$Value, warn = FALSE)

# Group by State and sum up the values
state_production <- production_data %>%
  group_by(State) %>%
  summarise(Total_Production = sum(Value, na.rm = TRUE)) %>%
  arrange(-Total_Production)

# Plotting the data
ggplot(state_production, aes(x=reorder(State, -Total_Production), y=Total_Production)) +
  geom_bar(stat="identity") +
  labs(title="Total Strawberry Production by State", x="State", y="Total Production") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
We can find the Massachusetts has the most Total Strawberry Production and West Virgina has the lowest Total Strawberry Production.

```{r}
# Filter and process data for sales
sales_data <- strawberry[grep('SALES', strawberry$Data.Item) & grep('\\$', strawberry$Data.Item),]
sales_data$Value <- as.numeric(sales_data$Value, warn = FALSE)
state_sales_by_year <- sales_data %>%
  group_by(State, Year) %>%
  summarise(Total_Sales = sum(Value, na.rm = TRUE))

# Plotting the data
ggplot(state_sales_by_year, aes(x = as.factor(Year), y = State, fill = Total_Sales)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  labs(title="Strawberry Sales by State and Year", 
       x="Year", y="State", fill="Total Sales") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The heatmap visualizes strawberry sales across states and years. Each tile in the heatmap corresponds to sales for a particular state in a specific year. The color intensity of each tile indicates the volume of sales, with darker colors representing higher sales. We can find that in 2018 the California has the best Strawberry Sales.



For the survey portion of the data, we process it by splitting the chemical composition into two columns and removing irrelevant variables.

```{r}
stb_survey <- strwb_survey %>%
  filter(str_detect(`Data Item`, "MEASURED IN")) %>%
  mutate(`Data Item` = str_extract(`Data Item`, "(?<=MEASURED IN ).*"))
stb_survey <- stb_survey %>%
  mutate(
    Chemical = if_else(str_detect(`Domain Category`, "\\(.*=.*\\)"),
                       str_extract(`Domain Category`, "(?<=\\().*?(?=\\=)"),
                       NA_character_),
    Chemical_Code = if_else(str_detect(`Domain Category`, "\\(.*=.*\\)"),
                            str_extract(`Domain Category`, "(?<=\\=).*?(?=\\))"),
                            NA_character_)
  )


stb_survey <- subset(stb_survey, select = -Program)
stb_survey <- subset(stb_survey, select = -`Domain Category`)
```

Missing Values, Outliers, and Duplicates
```{r}
stb_survey <- stb_survey[, !sapply(stb_survey, function(col) all(is.na(col)))]


stb_survey <- stb_survey[!is.na(stb_survey$Value), ]


stb_survey <- stb_survey[stb_survey$State != "OTHER STATES", ]


```

```{r}
strwb_census$`CV (%)`<- as.numeric(strwb_census$`CV (%)`)
strwb_census <- strwb_census %>%
  select(-Program,-`Period`,-Fruit,-crop_type,-Domain,-`Domain Category`)

```

```{r}
stb_survey$Domain <- gsub("CHEMICAL,", "", stb_survey$Domain)
stb_survey$Domain <- trimws(stb_survey$Domain)
#write.csv(stb_survey,"stb_survey.csv",row.names = F)

# Count the occurrences of each chemical
chemical_counts <- stb_survey %>%
  filter(!is.na(Chemical)) %>%
  group_by(Chemical) %>%
  tally(sort = TRUE) %>%
  top_n(10)  # Display top 10 for brevity

# Plotting the data
ggplot(chemical_counts, aes(x = reorder(Chemical, n), y = n)) +
  geom_bar(stat="identity") +
  coord_flip() +  # Flip coordinates for better display
  labs(title="Top 10 Chemicals Used", x="Chemical", y="Count") +
  theme_minimal()
```




```{r, fig.width=40, fig.height=20}
chemical_freq <- table(stb_survey$Chemical)

# Determine top and bottom chemicals based on frequency
top_chemicals <- names(sort(chemical_freq, decreasing = TRUE)[1:20])
bottom_chemicals <- names(sort(chemical_freq)[1:10])

# Combine top and bottom chemicals
chem_selection <- c(top_chemicals, bottom_chemicals)

# Filter the dataset based on selected chemicals
subset_stb_survey <- subset(stb_survey, Chemical %in% chem_selection)

library(RColorBrewer)
p=ggplot(subset_stb_survey, aes(x = Chemical, fill = Domain)) +
  geom_bar(show.legend = TRUE) +
  scale_x_discrete(limits = chem_selection) +
  scale_fill_brewer(palette = "Set3") +  
  labs(title = "Frequency of Chemicals by Domain", x = "Chemical", y = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ Year, scales = "free_y")  
p


```
In the 4 years, the initial set of 20 chemicals, such as "MALATHION" and "2,4-D," primarily corresponds to the categories of "FIELD CROPS" and "FRUIT & TREE NUTS."

In contrast, the chemicals with the lowest frequencies, like "CHLORPYRIFOS METHYL" and "DIAZINON," exhibit lower occurrence rates but are linked to various domains. Specific domains, such as "FRUIT & TREE NUTS" and "FIELD CROPS," are common across multiple chemicals, while others appear less frequently.


```{r}
# Line chart for Chemical Use Over Time
ggplot(subset_stb_survey, aes(x = Year, fill = Chemical)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(breaks = unique(subset_stb_survey$Year)) + 
  labs(title = "Chemical Use Over Time", y = "Frequency", x = "Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
This plot provides insights into the temporal trends and patterns of chemical usage in strawberry cultivation. We can find that in 2019, almost every chemical use reachs the most,so we should focus on this year.



```{r}
ggplot(stb_survey) +
  aes(x = Value, y = Year, fill = State, colour = State) +
  geom_point(shape = "circle", size = 1.5) +
  scale_fill_hue(direction = 1) +
  scale_color_hue(direction = 1) +
  labs(title = "Value and Year") +
  theme_minimal()
```
Value varies significantly among states, with notable differences in its distribution. Certain states, such as Florida and Washington, D.C., exhibit more extensive Value ranges, signifying greater variability in the data within these regions. While the majority of states tend to have median Values on the lower end, there are a few exceptions with higher median Values.




## References
https://quickstats.nass.usda.gov/src/glossary.pdf
https://quickstats.nass.usda.gov/param_define


